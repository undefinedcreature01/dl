{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logic gate models\n",
    "\n",
    "Machine learning models don't always have to be complex, for example logic gate models are very intuitive and easys to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make one for the XOR gate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Input 1 | Input 2 | Output |\n",
    "|---------|---------|--------|\n",
    "|    0    |    0    |    0   |\n",
    "|    0    |    1    |    1   |\n",
    "|    1    |    0    |    1   |\n",
    "|    1    |    1    |    0   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../assets/xor.jpg\" height=\"200px\" width=\"680px\">\n",
    "\n",
    "\n",
    ">[! image source !](https://towardsdatascience.com/cross-entropy-loss-function-f38c4ec8643e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XORModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XORModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 2) #this is the first layer - it takes in 2 inputs (our x1 and x2) (one node for each) - each node sends its output to every node in the next layer\n",
    "        self.fc2 = nn.Linear(2, 1) #second layer recieves 2 inputs - and then sends them to one output node\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x)) #sigmoid activation function\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "truth_labels = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
    "x_values = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick our loss function. For such simple problems brining in sigmoid or ReLu is not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's creat a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_model = XORModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_algorithm = torch.optim.SGD(xor_model.parameters(), lr=0.1) #bind it to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2501 epoch 1000\n",
      "Loss: 0.2500 epoch 2000\n",
      "Loss: 0.2499 epoch 3000\n",
      "Loss: 0.2498 epoch 4000\n",
      "Loss: 0.2495 epoch 5000\n",
      "Loss: 0.2488 epoch 6000\n",
      "Loss: 0.2466 epoch 7000\n",
      "Loss: 0.2403 epoch 8000\n",
      "Loss: 0.2259 epoch 9000\n",
      "Loss: 0.2057 epoch 10000\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 10000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    outputs = xor_model(x_values)\n",
    "    loss = loss_function(outputs, truth_labels)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimization_algorithm.zero_grad()\n",
    "    loss.backward()\n",
    "    optimization_algorithm.step()\n",
    "    \n",
    "    if (epoch+1) % 1000 == 0:\n",
    "        print(f'Loss: {loss.item():.4f} epoch {epoch+1}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our loss is still quite high, let's test it anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Output:\n",
      "| Input 1 | Input 2 | Predicted Output |\n",
      "|---------|---------|------------------|\n",
      "|    0    |    0    |         0        |\n",
      "|    0    |    1    |         1        |\n",
      "|    1    |    0    |         1        |\n",
      "|    1    |    1    |         1        |\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_output = xor_model(x_values)\n",
    "    predicted = (test_output > 0.5).float()\n",
    "\n",
    "    print(\"Predicted Output:\")\n",
    "    print(\"| Input 1 | Input 2 | Predicted Output |\")\n",
    "    print(\"|---------|---------|------------------|\")\n",
    "    for i in range(len(x_values)):\n",
    "        print(f\"|    {int(x_values[i][0])}    |    {int(x_values[i][1])}    |         {int(predicted[i][0])}        |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm this is all kinds of wrong. Such a simple concept yet our model hasn't really prefected anything withing 1000 iterations ?.\n",
    "\n",
    "Let's try changing both of the hyperparameters the learning rete and the number of loops, because in our models defense 0.1 is quite a high jump and 10000 is not that many iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_algorithm = torch.optim.SGD(xor_model.parameters(), lr=0.01) #bind it to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1887 epoch 10000\n",
      "Loss: 0.1726 epoch 20000\n",
      "Loss: 0.1497 epoch 30000\n",
      "Loss: 0.1100 epoch 40000\n",
      "Loss: 0.0683 epoch 50000\n",
      "Loss: 0.0424 epoch 60000\n",
      "Loss: 0.0286 epoch 70000\n",
      "Loss: 0.0208 epoch 80000\n",
      "Loss: 0.0160 epoch 90000\n",
      "Loss: 0.0129 epoch 100000\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 100000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    outputs = xor_model(x_values)\n",
    "    loss = loss_function(outputs, truth_labels)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimization_algorithm.zero_grad()\n",
    "    loss.backward()\n",
    "    optimization_algorithm.step()\n",
    "    \n",
    "    if (epoch+1) % 10000 == 0:\n",
    "        print(f'Loss: {loss.item():.4f} epoch {epoch+1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it now ? The loss seems to have gone down by a lot - it is basically 0 now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Output:\n",
      "| Input 1 | Input 2 | Predicted Output |\n",
      "|---------|---------|------------------|\n",
      "|    0    |    0    |         0        |\n",
      "|    0    |    1    |         1        |\n",
      "|    1    |    0    |         1        |\n",
      "|    1    |    1    |         0        |\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_output = xor_model(x_values)\n",
    "    predicted = (test_output > 0.5).float()\n",
    "\n",
    "    print(\"Predicted Output:\")\n",
    "    print(\"| Input 1 | Input 2 | Predicted Output |\")\n",
    "    print(\"|---------|---------|------------------|\")\n",
    "    for i in range(len(x_values)):\n",
    "        print(f\"|    {int(x_values[i][0])}    |    {int(x_values[i][1])}    |         {int(predicted[i][0])}        |\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
